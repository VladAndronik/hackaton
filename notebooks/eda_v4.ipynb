{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "FIGSIZE=(20,10)\n",
    "SEED=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# pool of regressors\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'Energy_consumption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_initial = pd.read_csv('../data/train.csv')\n",
    "test_initial = pd.read_csv('../data/test.csv')\n",
    "\n",
    "X_test = test_initial.drop('Id', axis=1)\n",
    "\n",
    "X = train_initial.drop(['Id', target], axis=1)\n",
    "y = train_initial[target].values.reshape(-1,1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=SEED,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catcols = X_train.select_dtypes(include='object').columns\n",
    "onehot = OneHotEncoder()\n",
    "\n",
    "train_trans = pd.DataFrame(onehot.fit_transform(X_train[catcols]).toarray())\n",
    "test_trans = pd.DataFrame(onehot.transform(X_valid[catcols]).toarray())\n",
    "\n",
    "X_train = pd.concat([X_train.drop(catcols, axis=1).reset_index(drop=True), \n",
    "                     train_trans], axis=1)\n",
    "\n",
    "X_valid = pd.concat([X_valid.drop(catcols, axis=1).reset_index(drop=True), \n",
    "                    test_trans], axis=1)\n",
    "\n",
    "\n",
    "catcols = X.select_dtypes(include='object').columns\n",
    "onehot = OneHotEncoder() \n",
    "\n",
    "train_trans = pd.DataFrame(onehot.fit_transform(X[catcols]).toarray())\n",
    "X_train_full = pd.concat([X.drop(catcols, axis=1).reset_index(drop=True),\n",
    "                    train_trans], axis=1)\n",
    "\n",
    "test_trans = pd.DataFrame(onehot.transform(X_test[catcols]).toarray())\n",
    "X_test = pd.concat([X_test.drop(catcols, axis=1).reset_index(drop=True), \n",
    "                    test_trans], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def prediction_cluster_folds(train_X, train_y, test_X,model,\n",
    "                            n_clusters=4,n_splits=5):\n",
    "    \"\"\"\n",
    "        train_X -- ndarray\n",
    "        train_y -- ndarray with (n, 1) shape\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED)\n",
    "    predicted_target = kmeans.fit(train_y).predict(train_y)\n",
    "    \n",
    "    predictions_holdout = np.zeros((test_X.shape[0], 1))\n",
    "    predictions_val = np.zeros((train_X.shape[0], 1))\n",
    "\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "    for (tr_ind, val_ind) in skf.split(train_X, predicted_target):\n",
    "        X_train_fold = train_X[tr_ind]\n",
    "        y_train_fold = np.squeeze(train_y[tr_ind])\n",
    "\n",
    "        X_valid_fold = train_X[val_ind]\n",
    "        y_valid_fold = np.squeeze(train_y[val_ind])\n",
    "\n",
    "        model_fold = clone(model)\n",
    "        y_pred = model_fold.fit(X_train_fold, y_train_fold).predict(X_valid_fold).reshape(-1,1)\n",
    "        scores.append(mean_squared_error(y_valid_fold, y_pred))\n",
    "        predictions_val[val_ind] = y_pred\n",
    "\n",
    "        y_pred_holdout = model_fold.predict(test_X).reshape(-1,1)\n",
    "        predictions_holdout += y_pred_holdout\n",
    "        \n",
    "    \n",
    "    predictions_holdout /= skf.n_splits\n",
    "    return predictions_holdout, scores, predictions_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_cluster_folds_ensemble(train_X, train_y, test_X, models, \n",
    "                                      n_clusters=4,n_splits=5,\n",
    "                                     seed=SEED):\n",
    "    \"\"\"\n",
    "        train_X -- ndarray\n",
    "        train_y -- ndarray with (n, 1) shape\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED)\n",
    "    predicted_target = kmeans.fit(train_y).predict(train_y)\n",
    "    \n",
    "    predictions_holdout = np.zeros((test_X.shape[0], 1))\n",
    "    predictions_val = np.zeros((train_X.shape[0], 1))\n",
    "\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    for (tr_ind, val_ind) in tqdm_notebook(skf.split(train_X, predicted_target), \n",
    "                                           total=skf.n_splits):\n",
    "        X_train_fold = train_X[tr_ind]\n",
    "        y_train_fold = np.squeeze(train_y[tr_ind])\n",
    "\n",
    "        X_valid_fold = train_X[val_ind]\n",
    "        y_valid_fold = np.squeeze(train_y[val_ind])\n",
    "        \n",
    "        # ensembling weighting average\n",
    "        pred_test_inline = np.zeros((test_X.shape[0], 1))\n",
    "        pred_val_inline = np.zeros((X_valid_fold.shape[0], 1))\n",
    "        weight_sum = 0\n",
    "        for (type_model, alpha, model) in models:\n",
    "            if type_model == 1:\n",
    "                model_fold = clone(model)\n",
    "                y_pred = model_fold.fit(X_train_fold, y_train_fold).predict(X_valid_fold).reshape(-1,1)\n",
    "                pred_val_inline += alpha * y_pred\n",
    "\n",
    "                y_pred = model_fold.predict(test_X).reshape(-1,1)\n",
    "                pred_test_inline += alpha * y_pred\n",
    "                weight_sum += alpha\n",
    "            else:\n",
    "                y_pred = model.fit(X_train_fold, y_train_fold, \n",
    "                                   X_valid_fold, y_valid_fold).predict(X_valid_fold)\n",
    "                pred_val_inline += alpha * y_pred\n",
    "                \n",
    "                y_pred = model.predict(test_X)\n",
    "                pred_test_inline += alpha * y_pred\n",
    "                weight_sum += alpha\n",
    "        \n",
    "        pred_test_inline /= weight_sum\n",
    "        pred_val_inline /= weight_sum\n",
    "        ####\n",
    "        predictions_val[val_ind] = pred_val_inline\n",
    "        \n",
    "        scores.append(mean_squared_error(y_valid_fold, pred_val_inline))\n",
    "        predictions_holdout += pred_test_inline\n",
    "        \n",
    "    \n",
    "    predictions_holdout /= skf.n_splits\n",
    "    return predictions_holdout, scores, predictions_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "zoo_models = [ (alpha, XGBRegressor(n_estimators=100, \n",
    "                             random_state=SEED, \n",
    "                             n_jobs=-1)),\n",
    "              (alpha, LGBMRegressor(n_estimators=100,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=SEED))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4d288be96d4bca9f2adb909d8b6054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = np.zeros((X_test.shape[0], 1))\n",
    "predictions_val = np.zeros((X_train_full.shape[0], 1))\n",
    "\n",
    "t = 10\n",
    "\n",
    "for i in tqdm_notebook(range(t), total=t):\n",
    "    y_pred, scores, y_pred_val = prediction_cluster_folds_ensemble(X_train_full.values, y, \n",
    "                                                                   X_test.values,  \n",
    "                                                                   zoo_models,\n",
    "                                                                   n_clusters=4, \n",
    "                                                                   n_splits=7,\n",
    "                                                                   seed=SEED+i)\n",
    "    predictions_test += y_pred\n",
    "    predictions_val += y_pred_val\n",
    "    \n",
    "predictions_test /= t\n",
    "predictions_val /= t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648459.1982865153"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_initial['Id'], columns=['Id'])\n",
    "submission[target] = predictions_test\n",
    "submission.to_csv('../data/submissions/xgb_lgb_oob_10seeds_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model(input_shape):\n",
    "    inps = Input(shape=input_shape)\n",
    "    x = Dense(256, activation='relu')(inps)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1)(x)\n",
    "    model = Model(inputs=inps, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=1e-3),\n",
    "        loss=['mse']\n",
    "    )\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2d1d214aa34d4f9991d5eb93aa8393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00129: early stopping\n",
      "598808.7256662837\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00117: early stopping\n",
      "844159.3100097971\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00140: early stopping\n",
      "729846.4908513356\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00123: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00133: early stopping\n",
      "694877.6145774748\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00127: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 00147: early stopping\n",
      "632217.2313298328\n",
      "Average MSE: 699981.8744869448\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_predictions = []\n",
    "metric_results = []\n",
    "scaler = StandardScaler()\n",
    "X_array = scaler.fit_transform(X_train_full.values)\n",
    "X_test_array = scaler.transform(X_test.values)\n",
    "\n",
    "for ind, (tr, val) in tqdm_notebook(enumerate(kf.split(X_array)), total=kf.n_splits):\n",
    "    X_tr = X_array[tr]\n",
    "    y_tr = y[tr]\n",
    "\n",
    "    X_vl = X_array[val]\n",
    "    y_vl = y[val]\n",
    "    \n",
    "    model = create_model((X_tr.shape[1],))\n",
    "    es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=50, verbose=0, \n",
    "                                 mode='auto', restore_best_weights=True)\n",
    "    rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, \n",
    "                                      mode='auto', verbose=0)\n",
    "    model.fit(\n",
    "        X_tr, y_tr, epochs=500, batch_size=256, validation_data=(X_vl, y_vl), verbose=False, callbacks=[es, rlr]\n",
    "    )\n",
    "    test_predictions.append(model.predict(X_test.values).flatten())\n",
    "    metric_results.append(mean_squared_error(y_vl, model.predict(X_vl).flatten()))\n",
    "    print(metric_results[-1])\n",
    "    \n",
    "print(f'Average MSE: {np.mean(metric_results)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN():\n",
    "    \n",
    "    def __init__(self, input_shape, epochs, batch_size, dropout=.2):\n",
    "        self.input_shape = input_shape\n",
    "        self.epochs = epochs\n",
    "        self.batch_size=batch_size\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        \n",
    "    def _init_model(self):\n",
    "        inps = Input(shape=self.input_shape)\n",
    "        x = Dense(256, activation='relu')(inps)\n",
    "        x = Dropout(self.dropout)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(.5 * self.dropout)(x)\n",
    "        x = Dense(1)(x)\n",
    "        model = Model(inputs=inps, outputs=x)\n",
    "        model.compile(\n",
    "            optimizer=Adam(lr=1e-3),\n",
    "            loss=['mse']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def fit(self, train_X, train_y, val_X, val_y):\n",
    "        self.model = self._init_model()\n",
    "\n",
    "        es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=50, verbose=0, \n",
    "                                     mode='auto', restore_best_weights=True)\n",
    "        rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, \n",
    "                                          mode='auto', verbose=0)\n",
    "        self.model.fit(\n",
    "            train_X, train_y, epochs=self.epochs, batch_size=self.batch_size, \n",
    "            validation_data=(val_X, val_y), verbose=False, \n",
    "            callbacks=[es, rlr]\n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_X):\n",
    "        pred = self.model.predict(test_X).flatten().reshape(-1,1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "zoo_models = [ (1,alpha, XGBRegressor(n_estimators=100, \n",
    "                             random_state=SEED, \n",
    "                             n_jobs=-1)),\n",
    "              (1,alpha, LGBMRegressor(n_estimators=100,\n",
    "                           n_jobs=-1,\n",
    "                           random_state=SEED)),\n",
    "              (0, alpha, NN(input_shape=(X_array.shape[1],), epochs=500, batch_size=256))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184eb3853cda4a4697aef22fc3bb9a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred, scores, y_pred_val = prediction_cluster_folds_ensemble(X_array, y, \n",
    "                                                               X_test_array,  \n",
    "                                                               zoo_models,\n",
    "                                                               n_clusters=4, \n",
    "                                                               n_splits=7,\n",
    "                                                               seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643817.026045401"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a529f80d6bc04d7187249bd4e24e96a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80701c3b6e3b4613a5d5f8851d72bc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55179fe2b5b0480e82c75854dd83d042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c7ff24142c425aaffc61d49e9edaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ff1c508f8148cf8225587015943d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f67301db674338a4b26da0986da2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48679c9b8a9479bae42bc1f0e5932c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776912bbb03b4ba68601566f50208ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f312b7aba5cf48bdb6ba4e4c2979f203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089751723e724f73af8b4fa4ae29a8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b366fb341c974663b03a1741cc2c5d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = np.zeros((X_test_array.shape[0], 1))\n",
    "predictions_val = np.zeros((X_array.shape[0], 1))\n",
    "\n",
    "t = 10\n",
    "\n",
    "for i in tqdm_notebook(range(t), total=t):\n",
    "    y_pred, _, y_pred_val = prediction_cluster_folds_ensemble(X_array, y, \n",
    "                                                           X_test_array,  \n",
    "                                                           zoo_models,\n",
    "                                                           n_clusters=4, \n",
    "                                                           n_splits=7,\n",
    "                                                           seed=SEED+i)\n",
    "    predictions_test += y_pred\n",
    "    predictions_val += y_pred_val\n",
    "    \n",
    "predictions_test /= t\n",
    "predictions_val /= t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626093.5104983785"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_initial['Id'], columns=['Id'])\n",
    "submission[target] = predictions_test\n",
    "submission.to_csv('../data/submissions/xgb_lgb_oob_nn_10seeds_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying random subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subspace = [.3, .5, .6, .7, .8, .9, .95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19ebcda22ef4708a4fdf22025ed0e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 3\n",
    "subspace_res = {}\n",
    "for ss in tqdm_notebook(subspace, total=len(subspace)):\n",
    "    \n",
    "    pred_xgb = np.zeros((X_array.shape[0], 1))\n",
    "    pred_lgb = np.zeros((X_array.shape[0], 1))\n",
    "    pred_rf = np.zeros((X_array.shape[0], 1))\n",
    "    \n",
    "    for t in range(T):\n",
    "        rf = RandomForestRegressor(n_estimators=100, max_depth=3, max_features=ss, \n",
    "                                   random_state=SEED+t, n_jobs=-1)\n",
    "        _, _, y_pred_rf = prediction_cluster_folds(X_array, y, X_test_array, rf, \n",
    "                                                  n_clusters=4, \n",
    "                                                  n_splits=5)\n",
    "        pred_rf += y_pred_rf\n",
    "        \n",
    "        rf = LGBMRegressor(n_estimators=100, colsample_bytree=ss, \n",
    "                           random_state=SEED+t, n_job=-1)\n",
    "        _, _, y_pred_lgb = prediction_cluster_folds(X_array, y, X_test_array, rf, \n",
    "                                                  n_clusters=4, \n",
    "                                                  n_splits=5)\n",
    "        pred_lgb += y_pred_lgb\n",
    "        \n",
    "        rf = XGBRegressor(n_estimators=100, colsample_bytree=ss, \n",
    "                          random_state=SEED+t, n_jobs=-1)\n",
    "        _, _, y_pred_xgb = prediction_cluster_folds(X_array, y, X_test_array, rf, \n",
    "                                                  n_clusters=4, \n",
    "                                                  n_splits=5)\n",
    "        pred_xgb += y_pred_xgb\n",
    "    \n",
    "    pred_xgb /= T\n",
    "    pred_lgb /= T\n",
    "    pred_rf /= T\n",
    "    score_xgb = mean_squared_error(y, pred_xgb)\n",
    "    score_lgb = mean_squared_error(y, pred_lgb)\n",
    "    score_rf = mean_squared_error(y, pred_rf)\n",
    "        \n",
    "    subspace_res[ss] = (score_xgb, score_lgb, score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJcAAAI/CAYAAADKljhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb_scores = [v[0] for v in subspace_res.values()]\n",
    "lgb_scores = [v[1] for v in subspace_res.values()]\n",
    "rf_scores = [v[2] for v in subspace_res.values()]\n",
    "\n",
    "plt.subplots(figsize=FIGSIZE)\n",
    "plt.plot(subspace, xgb_scores, label='xgb')\n",
    "plt.plot(subspace, lgb_scores, label='lgb')\n",
    "# plt.plot(subspace, rf_scores, label='rf')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "zoo_models = [ (1,alpha, XGBRegressor(n_estimators=100, colsample_bytree=.3,\n",
    "                             random_state=SEED,\n",
    "                             n_jobs=-1)),\n",
    "              \n",
    "              (1,alpha, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.3,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+1)),\n",
    "              \n",
    "              (1,.7 * alpha, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.4,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+2)),\n",
    "              \n",
    "              (1, .7 * alpha, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.5,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+3)),\n",
    "              (0, alpha, NN(input_shape=(X_array.shape[1],), epochs=500, batch_size=256))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e582f2b1a84a45afa78a1dd81e5a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75add6cb58074d5e8cc3b9c492f76483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1aaef38ad84d55805df4ec00b8481e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e245b3e052545a18733f9bcd4e9e81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016a5e3443d44e989b2c97492ab8fc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c45c004fcd7464f90e8baad72d4b08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d68d7c69b4745e28fed03b9d8d9ad99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fbd9b6313347a8a6e8c616a680337b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f690f76f9a45869b9bcec903dd7ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdc405d66e54fb4b92fa276e3fa66fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9455970653442b95160b69e808dfe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_test = np.zeros((X_test_array.shape[0], 1))\n",
    "predictions_val = np.zeros((X_array.shape[0], 1))\n",
    "\n",
    "t = 10\n",
    "\n",
    "for i in tqdm_notebook(range(t), total=t):\n",
    "    y_pred, _, y_pred_val = prediction_cluster_folds_ensemble(X_array, y, \n",
    "                                                           X_test_array,  \n",
    "                                                           zoo_models,\n",
    "                                                           n_clusters=4, \n",
    "                                                           n_splits=7,\n",
    "                                                           seed=SEED+i)\n",
    "    predictions_test += y_pred\n",
    "    predictions_val += y_pred_val\n",
    "    \n",
    "predictions_test /= t\n",
    "predictions_val /= t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620733.0398620749"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, predictions_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_initial['Id'], columns=['Id'])\n",
    "submission[target] = predictions_test\n",
    "submission.to_csv('../data/submissions/xgb_lgb_rnd_subs_nn_10seeds_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "zoo_models = [ (1,alpha, XGBRegressor(n_estimators=100, colsample_bytree=.3,\n",
    "                             random_state=SEED,\n",
    "                             n_jobs=-1)),\n",
    "              \n",
    "              (1,alpha, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.3,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+1)),\n",
    "              \n",
    "              (1,.7 * alpha, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.4,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+2)),\n",
    "              \n",
    "              (1, .7 * alpha, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.5,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+3)),\n",
    "              (0, alpha, NN(input_shape=(X_array.shape[1],), epochs=500, batch_size=256))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meta_transformer(train_X, train_y, test_X, \n",
    "                       models, n_clusters=4,n_splits=5, seed=SEED):\n",
    "    \"\"\"\n",
    "        train_X -- ndarray\n",
    "        train_y -- ndarray with (n, 1) shape\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=SEED)\n",
    "    predicted_target = kmeans.fit(train_y).predict(train_y)\n",
    "    \n",
    "    \n",
    "    num_models = len(models)\n",
    "    meta_matrix_train = np.zeros((train_X.shape[0], num_models))\n",
    "    meta_matrix_test = np.zeros((test_X.shape[0], num_models))\n",
    "\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    for (tr_ind, val_ind) in tqdm_notebook(skf.split(train_X, predicted_target), \n",
    "                                           total=skf.n_splits):\n",
    "        X_train_fold = train_X[tr_ind]\n",
    "        y_train_fold = np.squeeze(train_y[tr_ind])\n",
    "\n",
    "        X_valid_fold = train_X[val_ind]\n",
    "        y_valid_fold = np.squeeze(train_y[val_ind])\n",
    "        \n",
    "        for i,(type_model, model) in enumerate(models):\n",
    "            if type_model == 1:\n",
    "                model_fold = clone(model)\n",
    "                y_pred_valid = model_fold.fit(X_train_fold, \n",
    "                                              y_train_fold).predict(X_valid_fold)\n",
    "                meta_matrix_train[val_ind, i] = y_pred_valid\n",
    "                \n",
    "                \n",
    "                y_pred_test = model_fold.predict(test_X)\n",
    "                meta_matrix_test[:, i] = y_pred_test\n",
    "            else:\n",
    "                y_pred_valid = model.fit(X_train_fold, y_train_fold, \n",
    "                                   X_valid_fold, y_valid_fold).predict(X_valid_fold)\n",
    "                meta_matrix_train[val_ind, i] = np.squeeze(y_pred_valid)\n",
    "\n",
    "                y_pred_test = model.predict(test_X)\n",
    "                meta_matrix_test[:, i] = np.squeeze(y_pred_test)\n",
    "                \n",
    "    return meta_matrix_train, meta_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meta_transform_mean(train_X, train_y, test_X, models,\n",
    "                        num_iterations=10,\n",
    "                        n_clusters=4,n_splits=7, seed=SEED):\n",
    "    \n",
    "    train_meta = np.zeros((train_X.shape[0], len(models)))\n",
    "    test_meta = np.zeros((test_X.shape[0], len(models)))\n",
    "    \n",
    "    for t in range(num_iterations):\n",
    "        train_meta_curr, test_meta_curr = meta_transformer(X_array, y, X_test_array, \n",
    "                                                         models, n_clusters=n_clusters, n_splits=n_splits,\n",
    "                                                          seed=seed+t)\n",
    "        train_meta += train_meta_curr\n",
    "        test_meta += test_meta_curr\n",
    "        \n",
    "    train_meta /= num_iterations\n",
    "    test_meta /= num_iterations\n",
    "    \n",
    "    return train_meta, test_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models_check = [\n",
    "    (1,XGBRegressor(n_estimators=100, colsample_bytree=.3,\n",
    "                             random_state=SEED,\n",
    "                             n_jobs=-1)),\n",
    "              \n",
    "    (1, LGBMRegressor(n_estimators=100,\n",
    "                      colsample_bytree=.3,\n",
    "                       n_jobs=-1,\n",
    "                       random_state=SEED+1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c230708df02048b78ad66e51fab37a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "664838.0907035497"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, scores, _ = prediction_cluster_folds_ensemble(X_array, y, \n",
    "                                               X_test_array,  \n",
    "                                               models_check,\n",
    "                                               n_clusters=4, \n",
    "                                               n_splits=7,\n",
    "                                               seed=SEED)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b0b80ac524271a21837690fb015e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a2bbe1668c4470854df2c4c5fc50ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_meta, test_meta = meta_transform_mean(X_array, y,\n",
    "                                           X_test_array, models_check,\n",
    "                                           num_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "ridge = Ridge(alpha=2., random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "643329.9814622458"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, scores, _ = prediction_cluster_folds(train_meta, y, \n",
    "                                       test_meta,  \n",
    "                                       ridge,\n",
    "                                       n_clusters=4, \n",
    "                                       n_splits=7)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha=0.5\n",
    "\n",
    "zoo_models = [ (1, XGBRegressor(n_estimators=100, colsample_bytree=.3,\n",
    "                             random_state=SEED,\n",
    "                             n_jobs=-1)),\n",
    "              \n",
    "              (1, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.3,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+1)),\n",
    "              \n",
    "              (1, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.4,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+2)),\n",
    "              \n",
    "              (1, LGBMRegressor(n_estimators=100,\n",
    "                                      colsample_bytree=.5,\n",
    "                                       n_jobs=-1,\n",
    "                                       random_state=SEED+3)),\n",
    "              \n",
    "              (0, NN(input_shape=(X_array.shape[1],), epochs=500, \n",
    "                     batch_size=256, dropout=.2)),\n",
    "              \n",
    "              \n",
    "#               (0, NN(input_shape=(X_array.shape[1],), epochs=500, \n",
    "#                      batch_size=256, dropout=.5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8eb44514b1491f832e2629b87437f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-2051d49f0b97>\u001b[0m in \u001b[0;36mmeta_transform_mean\u001b[0;34m(train_X, train_y, test_X, models, num_iterations, n_clusters, n_splits, seed)\u001b[0m\n\u001b[1;32m      9\u001b[0m         train_meta_curr, test_meta_curr = meta_transformer(X_array, y, X_test_array, \n\u001b[1;32m     10\u001b[0m                                                          \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                                           seed=seed+t)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_meta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_meta_curr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_meta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_meta_curr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-e1990bc4e8bf>\u001b[0m in \u001b[0;36mmeta_transformer\u001b[0;34m(train_X, train_y, test_X, models, n_clusters, n_splits, seed)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 y_pred_valid = model.fit(X_train_fold, y_train_fold, \n\u001b[0;32m---> 38\u001b[0;31m                                    X_valid_fold, y_valid_fold).predict(X_valid_fold)\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mmeta_matrix_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-3259550afb8b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_X, train_y, val_X, val_y)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_meta, test_meta = meta_transform_mean(X_array, y,\n",
    "                                           X_test_array, zoo_models,\n",
    "                                           num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "ridge = Ridge(alpha=10., random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618168.5825555118"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, scores, _ = prediction_cluster_folds(train_meta, y, \n",
    "                                       test_meta,  \n",
    "                                       ridge,\n",
    "                                       n_clusters=4, \n",
    "                                       n_splits=7)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10., random_state=SEED)\n",
    "y_pred = ridge.fit(train_meta, y).predict(test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_initial['Id'], columns=['Id'])\n",
    "submission[target] = y_pred\n",
    "submission.to_csv('../data/submissions/xgb_lgb_rnd_subs_nn_stacking.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=10., random_state=SEED)\n",
    "y_pred = ridge.fit(train_meta, y).predict(test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_initial['Id'], columns=['Id'])\n",
    "submission[target] = y_pred\n",
    "submission.to_csv('../data/submissions/xgb_lgb_rnd_subs_nn_stacking_fitall.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_meta_df = pd.DataFrame(train_meta, columns = ['xgb_30', 'lgb_30', 'lgb_40', 'lgb_50', 'nn_v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_meta_df = pd.DataFrame(test_meta, columns = ['xgb_30', 'lgb_30', 'lgb_40', 'lgb_50', 'nn_v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta_df.to_csv('../data/train_meta_v1.csv', index=False)\n",
    "test_meta_df.to_csv('../data/test_meta_v1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
